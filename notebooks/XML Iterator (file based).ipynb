{
 "metadata": {
  "name": "",
  "signature": "sha256:00fbee87fc9c268318aa845c827795c9259b55972c7cbeb0f47ef416a82245f3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recursion testing using local files instead of URL requests\n",
      "\n",
      "(can we manage the catalogRef vs dataset links regardless?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from lxml import etree\n",
      "\n",
      "def generate_path(extension):\n",
      "    return os.path.join('xml_samples', extension)\n",
      "\n",
      "def request(path):\n",
      "    if not os.path.exists(path):\n",
      "        return ''\n",
      "    with open(path, 'r') as f:\n",
      "        text = f.read()\n",
      "    return text\n",
      "\n",
      "def parse_xml(text):\n",
      "    try:\n",
      "        return etree.fromstring(text)\n",
      "    except:\n",
      "        return None\n",
      "\n",
      "def extract_element_tag(tag):\n",
      "    if not tag:\n",
      "        return ''\n",
      "    return tag.split('}')[-1]    \n",
      "    \n",
      "class Crawl(object):\n",
      "    def __init__(self, path):\n",
      "        self.path = path\n",
      "        self.crawl()\n",
      "    \n",
      "    def _parse(self):\n",
      "        # parse the xml\n",
      "        url = generate_path(self.path)\n",
      "        response = request(url)\n",
      "        xml = parse_xml(response)\n",
      "        \n",
      "        return xml\n",
      "    \n",
      "    def crawl(self):\n",
      "        # start at the path, iterate through the catalogRefs\n",
      "        # and generate the tree of links\n",
      "        \n",
      "        xml = self._parse()\n",
      "        \n",
      "        \n",
      "        \n",
      "        \n",
      "        pass\n",
      "\n",
      "class CatalogRef(object):\n",
      "    def __init__(self, path, element):\n",
      "        self.path = path\n",
      "        self.element = element\n",
      "        \n",
      "    def _parse(self):\n",
      "        # parse the xml\n",
      "        \n",
      "        name = self.element.attrib.get('name', '')\n",
      "        cat_id = self.element.attrib.get('ID', '')\n",
      "        title = self.element.attrib.get('title', '')\n",
      "        href = self.element.attrib.get('href', '')\n",
      "        \n",
      "        # get the parent \n",
      "        parent = self.element.parent()\n",
      "        parent_tag = extract_element_tag(parent.tag)\n",
      "        if parent_tag != 'catalog':\n",
      "            parent_id = parent.attrib.get('ID', '')\n",
      "        \n",
      "        # nested catalogRefs\n",
      "        follows = self.element.xpath('*[local-name()=\"catalogRef\"]')\n",
      "        \n",
      "        description = {\n",
      "            'id': cat_id,\n",
      "            'href': href\n",
      "        }\n",
      "        if name:\n",
      "            description.update({'name': name})\n",
      "        if title:\n",
      "            description.update({'title': title})\n",
      "        if parent_id:\n",
      "            description.update({'parent': parent_id, 'parent_type': parent_tag})\n",
      "            \n",
      "        return description, follows\n",
      "        \n",
      "        \n",
      "class Dataset(object):\n",
      "    # where services is the list of bases for this example\n",
      "    def __init__(self, path, element, services):\n",
      "        self.path = path\n",
      "        self.element = element\n",
      "        self.services = services\n",
      "    \n",
      "    def _parse(self):\n",
      "        # parse the xml\n",
      "        name = self.element.attrib.get('name', '')\n",
      "        dataset_id = self.element.attrib.get('ID', '')\n",
      "        href = self.element.attrib.get('urlPath', '')\n",
      "        \n",
      "        # get the parent \n",
      "        parent = self.element.parent()\n",
      "        parent_tag = extract_element_tag(parent.tag)\n",
      "        if parent_tag != 'catalog':\n",
      "            parent_id = parent.attrib.get('ID', '')\n",
      "        \n",
      "        # nested catalogRefs\n",
      "        follows = self.element.xpath('*[local-name()=\"catalogRef\"]')\n",
      "        \n",
      "        hrefs= []\n",
      "        if href:\n",
      "            # do something about the services\n",
      "            hrefs = ['/'.join([service, href]) for service in services]\n",
      "        \n",
      "        date = next(iter(self.element.xpath('*[local-name()=\"date\"]/text()')), '')\n",
      "        \n",
      "        description = {\n",
      "            'id': dataset_id\n",
      "        }\n",
      "        if hrefs:\n",
      "            description.update({'hrefs': hrefs})\n",
      "        if name:\n",
      "            description.update({'name': name})\n",
      "        if date:\n",
      "            description.update({'date': date})\n",
      "            \n",
      "        if parent_id:\n",
      "            description.update({'parent': parent_id, 'parent_type': parent_tag})\n",
      "            \n",
      "        return description, follows\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-1-f38fa3e78138>, line 68)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f38fa3e78138>\"\u001b[0;36m, line \u001b[0;32m68\u001b[0m\n\u001b[0;31m    date = next(iter(self.element.xpath('*[local-name()=\"date\"]/text()')), 'missing')\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}